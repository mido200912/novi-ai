import os, json
import google.generativeai as genai
from sentence_transformers import SentenceTransformer, util
from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv
from fastapi.middleware.cors import CORSMiddleware

# âœ… Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ FastAPI
app = FastAPI(title="Kepler AI API")

# âœ… ØªÙØ¹ÙŠÙ„ CORS Ù„ØªØ³Ù…Ø­ Ø¨Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ù† React
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Ù…Ù…ÙƒÙ† ØªØ®ØµØµÙ‡Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¨Ù€ ["http://localhost:5173"]
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… ØªØ­Ù…ÙŠÙ„ Ù…ÙØªØ§Ø­ Gemini API
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# ğŸª ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨Ù„Ø±
with open("kepler_all_exoplanets.json", "r", encoding="utf-8") as f:
    planets = json.load(f)

# ğŸ§  Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆØ°Ø¬ embeddings
embedder = SentenceTransformer("all-MiniLM-L6-v2")

planet_texts = [
    f"{p.get('name', p.get('id'))}: radius {p.get('planet_radius_earth')} Earths, "
    f"temp {p.get('planet_temp_eq_K')} K, star temp {p.get('star_temp_K')} K, "
    f"status {p.get('status')}"
    for p in planets
]

embeddings = embedder.encode(planet_texts, convert_to_tensor=True)

# ğŸ” Ø¯Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
def search_local(query, top_k=5):
    q_emb = embedder.encode(query, convert_to_tensor=True)
    hits = util.semantic_search(q_emb, embeddings, top_k=top_k)[0]
    return "\n".join([planet_texts[h["corpus_id"]] for h in hits])

# ğŸª„ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙˆØ¯ÙŠÙ„ Gemini
model = genai.GenerativeModel("gemini-2.5-flash")

# ğŸ§© ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù€ Schema Ù„Ù„Ø·Ù„Ø¨
class Question(BaseModel):
    query: str

# âœ… Endpoint Ø±Ø¦ÙŠØ³ÙŠ Ù„Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
@app.post("/ask")
async def ask_gemini(data: Question):
    try:
        query = data.query
        local_context = search_local(query, top_k=8)

        prompt = (
            "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙ„ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„ÙƒÙˆØ§ÙƒØ¨ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© ÙˆØ§Ù„ÙØ¶Ø§Ø¡. "
            "Ø§Ø¹ØªÙ…Ø¯ Ø£ÙˆÙ„Ù‹Ø§ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ¨Ù„Ø± Ø§Ù„Ù…Ø±ÙÙ‚Ø©ØŒ Ø«Ù… ÙˆØ³Ù‘Ø¹ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø¹Ù„Ù…ÙŠÙ‹Ø§.\n\n"
            f"Ø³ÙŠØ§Ù‚ ÙƒØ¨Ù„Ø±:\n{local_context}\n\nØ³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {query}"
        )

        response = model.generate_content(prompt)
        return {"answer": response.text.strip()}
    except Exception as e:
        print("âŒ Error:", e)
        return {"error": str(e)}

# âœ… Ø¯Ø¹Ù… OPTIONS (Ø¹Ø´Ø§Ù† React ÙŠØ¹Ù…Ù„ preflight check)
@app.options("/ask")
async def options_handler():
    return {"ok": True}
